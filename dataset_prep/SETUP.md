# Dataset Setup Guide

This guide will help you download and prepare the AG News, IMDB, and Amazon datasets for your text AutoML experiments.

## Quick Setup (Recommended)

The easiest way to get started:

```bash
# Install requirements and download all datasets
python setup_data.py
```

This script will:
1. Check and install required packages
2. Download all three datasets (AG News, IMDB, Amazon)
3. Verify the downloads were successful
4. Tell you if everything is ready to use

## Manual Setup Options

If you prefer more control, you can use these individual scripts:

### Option 1: Using Hugging Face Datasets (Recommended)

```bash
# Install the datasets library
pip install datasets transformers

# Download all datasets
python download_with_huggingface.py

# Or download specific datasets
python download_with_huggingface.py --datasets ag_news imdb
```

### Option 2: Direct Downloads

```bash
# Download all datasets using direct URLs
python download_datasets.py

# Or download specific datasets
python download_datasets.py --datasets ag_news imdb
```

### Option 3: Custom Configuration

```bash
# Use custom data directory and seed
python download_with_huggingface.py --data-dir my_data --seed 123
```

## Verification

To check if your datasets were downloaded correctly:

```bash
# Verify all datasets
python verify_data.py

# Verify specific datasets
python verify_data.py --datasets ag_news imdb

# Verify with custom data directory
python verify_data.py --data-dir my_data
```

## Expected Directory Structure

After successful download, you should have:

```
data/
├── ag_news/
│   ├── train.csv
│   └── test.csv
├── imdb/
│   ├── train.csv
│   └── test.csv
├── amazon/
│   ├── train.csv
│   └── test.csv
└── temp/           # Temporary download files (can be deleted)
```

## Dataset Details

### AG News
- **Classes**: 4 (World, Sports, Business, Technology)
- **Task**: News article categorization
- **Size**: ~120,000 samples total
- **Source**: AG's corpus of news articles

### IMDB
- **Classes**: 2 (Positive, Negative)
- **Task**: Movie review sentiment analysis
- **Size**: ~50,000 samples total
- **Source**: Internet Movie Database reviews

### Amazon Reviews
- **Classes**: 5 (product categories or rating-based)
- **Task**: Product review classification
- **Size**: Variable (limited for memory efficiency)
- **Source**: Amazon product reviews or synthetic data

## Data Format

All datasets are saved as CSV files with these columns:
- `text`: The input text to classify
- `label`: The target class (integer, 0-indexed)

Example:
```csv
text,label
"This is a world news article about global events",0
"Sports team wins championship game",1
"Company reports quarterly earnings",2
"New technology breakthrough announced",3
```

## Troubleshooting

### Common Issues

1. **Internet Connection Problems**
   ```bash
   # Try the alternative download method
   python download_datasets.py
   ```

2. **Hugging Face Datasets Not Available**
   ```bash
   pip install datasets
   # Or use direct downloads
   python download_datasets.py
   ```

3. **Memory Issues with Large Datasets**
   - The scripts automatically limit dataset sizes for memory efficiency
   - Amazon dataset uses sampling to keep reasonable size

4. **Permission/Directory Issues**
   ```bash
   # Use a different data directory
   python setup_data.py --data-dir /path/to/your/data
   ```

### Manual Data Addition

If you have your own datasets, ensure they follow the CSV format:

```python
import pandas as pd

# Your data should look like this
df = pd.DataFrame({
    'text': ['Sample text 1', 'Sample text 2'],
    'label': [0, 1]
})

# Save in the expected location
df.to_csv('data/your_dataset/train.csv', index=False)
```

## Next Steps

Once your data is set up, you can run experiments:

```bash
# Test with AG News
python run_text.py --dataset ag_news

# Test with IMDB
python run_text.py --dataset imdb

# Test with Amazon reviews
python run_text.py --dataset amazon

# Run with custom parameters
python run_text.py --dataset ag_news --seed 123 --output-path my_predictions.npy
```

## Performance Tips

- **GPU Usage**: The system automatically detects and uses GPU if available
- **Memory Management**: Datasets are automatically sized for your system
- **Reproducibility**: Use consistent seeds across experiments
- **Parallel Processing**: The download scripts use progress bars and efficient processing

For any issues, check the logs generated by the scripts for detailed error messages.